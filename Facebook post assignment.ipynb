{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e9906c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow_addons import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab6cfe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5ae706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataset=pd.read_csv(\"FB_posts_labeled.txt\",delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8319b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_dataset=pd.read_csv(\"FB_posts_unlabeled.txt\",delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e883572",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_text=np.array(unlabeled_dataset['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d01cb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=np.array(labeled_dataset['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9785af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=np.array(labeled_dataset[['Appreciation','Complaint','Feedback']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27f2ea38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989cce7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postId</th>\n",
       "      <th>message</th>\n",
       "      <th>Appreciation</th>\n",
       "      <th>Complaint</th>\n",
       "      <th>Feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126016648090_10150802142013091</td>\n",
       "      <td>Great ! ;)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108381603303_10151136215833304</td>\n",
       "      <td>YUM! YUM!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108381603303_3913438087739</td>\n",
       "      <td>Yummm :))</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110455108974424_343049739048292</td>\n",
       "      <td>sweet</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110455108974424_350358541650745</td>\n",
       "      <td>nice</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            postId     message  Appreciation  Complaint  \\\n",
       "0   126016648090_10150802142013091  Great ! ;)             1          0   \n",
       "1   108381603303_10151136215833304   YUM! YUM!             1          0   \n",
       "2       108381603303_3913438087739   Yummm :))             1          0   \n",
       "3  110455108974424_343049739048292       sweet             1          0   \n",
       "4  110455108974424_350358541650745        nice             1          0   \n",
       "\n",
       "   Feedback  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0a8913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens = None,\n",
    "    standardize = 'lower_and_strip_punctuation',\n",
    "    split = 'whitespace',\n",
    "    ngrams = None,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = None\n",
    ")\n",
    "vectorize_layer.adapt(np.array(labeled_dataset['message']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aae7eed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'the',\n",
       " 'to',\n",
       " 'i',\n",
       " 'and',\n",
       " 'a',\n",
       " 'you',\n",
       " 'of',\n",
       " 'for',\n",
       " 'my',\n",
       " 'in',\n",
       " 'that',\n",
       " 'is',\n",
       " 'your',\n",
       " 'it',\n",
       " 'on',\n",
       " 'have',\n",
       " 'with',\n",
       " 'was',\n",
       " 'not',\n",
       " 'this',\n",
       " 'me',\n",
       " 'they',\n",
       " 'are',\n",
       " 'at',\n",
       " 'be',\n",
       " 'from',\n",
       " 'will',\n",
       " 'so',\n",
       " 'we',\n",
       " 'get',\n",
       " 'but',\n",
       " 'if',\n",
       " 'do',\n",
       " 'as',\n",
       " 'just',\n",
       " 'all',\n",
       " 'would',\n",
       " 'one',\n",
       " 'no',\n",
       " 'when',\n",
       " 'an',\n",
       " 'can',\n",
       " 'out',\n",
       " 'or',\n",
       " 'had',\n",
       " 'store',\n",
       " 'customer',\n",
       " 'there',\n",
       " 'what',\n",
       " 'our',\n",
       " 'up',\n",
       " 'dont',\n",
       " 'service',\n",
       " 'am',\n",
       " 'them',\n",
       " 'like',\n",
       " 'now',\n",
       " 'bank',\n",
       " 'their',\n",
       " 'about',\n",
       " 'time',\n",
       " 'been',\n",
       " 'by',\n",
       " 'has',\n",
       " 'how',\n",
       " 'know',\n",
       " 'its',\n",
       " 'us',\n",
       " 'why',\n",
       " 'flight',\n",
       " 'card',\n",
       " 'buy',\n",
       " 'because',\n",
       " 'back',\n",
       " 'please',\n",
       " 'were',\n",
       " 'love',\n",
       " 'im',\n",
       " 'people',\n",
       " 'who',\n",
       " 'more',\n",
       " 'he',\n",
       " 'only',\n",
       " 'thank',\n",
       " 'any',\n",
       " 'go',\n",
       " 'she',\n",
       " 'want',\n",
       " 'then',\n",
       " 'best',\n",
       " 'make',\n",
       " 'told',\n",
       " 'new',\n",
       " 'never',\n",
       " 'very',\n",
       " 'money',\n",
       " 'thanks',\n",
       " 'over',\n",
       " 'today',\n",
       " 'going',\n",
       " 'after',\n",
       " 'could',\n",
       " 'account',\n",
       " 'customers',\n",
       " 'got',\n",
       " 'again',\n",
       " 'other',\n",
       " 'help',\n",
       " 'really',\n",
       " 'some',\n",
       " 'business',\n",
       " 'great',\n",
       " 'way',\n",
       " 'her',\n",
       " 'good',\n",
       " 'should',\n",
       " 'need',\n",
       " 'even',\n",
       " 'did',\n",
       " 'off',\n",
       " 'america',\n",
       " '2',\n",
       " 'company',\n",
       " 'cant',\n",
       " 'take',\n",
       " 'use',\n",
       " 'well',\n",
       " 'still',\n",
       " 'name',\n",
       " 'much',\n",
       " 'than',\n",
       " 'day',\n",
       " 'another',\n",
       " 'products',\n",
       " 'right',\n",
       " 'call',\n",
       " 'target',\n",
       " 'does',\n",
       " 'which',\n",
       " 'support',\n",
       " 'being',\n",
       " 'see',\n",
       " 'said',\n",
       " 'last',\n",
       " 'work',\n",
       " '3',\n",
       " 'years',\n",
       " 'phone',\n",
       " 'called',\n",
       " 'think',\n",
       " 'online',\n",
       " 'find',\n",
       " 'pay',\n",
       " 'guys',\n",
       " 'say',\n",
       " 'went',\n",
       " 'credit',\n",
       " 'made',\n",
       " 'his',\n",
       " 'family',\n",
       " 'give',\n",
       " 'here',\n",
       " 'check',\n",
       " 'home',\n",
       " 'since',\n",
       " 'ever',\n",
       " 'also',\n",
       " 'stores',\n",
       " 'dole',\n",
       " 'human',\n",
       " 'first',\n",
       " 'every',\n",
       " 'many',\n",
       " 'same',\n",
       " 'rights',\n",
       " 'cvs',\n",
       " 'trying',\n",
       " 'shop',\n",
       " 'where',\n",
       " 'ive',\n",
       " 'days',\n",
       " 'until',\n",
       " 'order',\n",
       " 'walgreens',\n",
       " 'problem',\n",
       " 'united',\n",
       " 'two',\n",
       " 'tell',\n",
       " 'into',\n",
       " 'these',\n",
       " 'someone',\n",
       " 'airlines',\n",
       " 'fly',\n",
       " 'didnt',\n",
       " 'before',\n",
       " 'walmart',\n",
       " 'southwest',\n",
       " 'free',\n",
       " 'year',\n",
       " 'shopping',\n",
       " 'brief',\n",
       " 'him',\n",
       " 'delta',\n",
       " 'better',\n",
       " 'away',\n",
       " 'american',\n",
       " 'number',\n",
       " 'always',\n",
       " 'through',\n",
       " 'stop',\n",
       " 'put',\n",
       " 'purchase',\n",
       " 'hours',\n",
       " 'price',\n",
       " 'care',\n",
       " 'come',\n",
       " 'let',\n",
       " 'sure',\n",
       " 'getting',\n",
       " 'something',\n",
       " 'employees',\n",
       " 'coupon',\n",
       " 'too',\n",
       " 'macys',\n",
       " 'wont',\n",
       " 'long',\n",
       " 'food',\n",
       " 'coupons',\n",
       " 'pepsi',\n",
       " 'asked',\n",
       " 'shell',\n",
       " 'email',\n",
       " 'week',\n",
       " 'thing',\n",
       " 'keep',\n",
       " 'nothing',\n",
       " 'manager',\n",
       " 'experience',\n",
       " 'anyone',\n",
       " '5',\n",
       " 'hold',\n",
       " 'airline',\n",
       " 'down',\n",
       " 'sale',\n",
       " 'change',\n",
       " 'wanted',\n",
       " 'next',\n",
       " 'bad',\n",
       " 'anything',\n",
       " 'used',\n",
       " 'website',\n",
       " 'most',\n",
       " 'doesnt',\n",
       " 'case',\n",
       " 'took',\n",
       " 'having',\n",
       " 'while',\n",
       " 'minutes',\n",
       " 'lost',\n",
       " 'times',\n",
       " 'gift',\n",
       " 'hope',\n",
       " 'u',\n",
       " 'longer',\n",
       " 'bought',\n",
       " 'able',\n",
       " 'pull',\n",
       " 'wait',\n",
       " 'tried',\n",
       " 'month',\n",
       " 'return',\n",
       " 'safeway',\n",
       " '1',\n",
       " 'worst',\n",
       " 'without',\n",
       " 'using',\n",
       " 'line',\n",
       " 'doing',\n",
       " 'corporate',\n",
       " 'policy',\n",
       " 'kiobel',\n",
       " 'everyone',\n",
       " 'received',\n",
       " 'making',\n",
       " 'done',\n",
       " 'paid',\n",
       " 'page',\n",
       " '10',\n",
       " 'old',\n",
       " 'flights',\n",
       " 'crimes',\n",
       " 'happy',\n",
       " 'charge',\n",
       " 'such',\n",
       " 'nice',\n",
       " 'gmos',\n",
       " 'boa',\n",
       " 'abuses',\n",
       " 'kohls',\n",
       " 'those',\n",
       " 'local',\n",
       " 'kelloggs',\n",
       " 'issue',\n",
       " 'wrong',\n",
       " 'due',\n",
       " '4',\n",
       " 'working',\n",
       " 'amicus',\n",
       " 'yet',\n",
       " 'place',\n",
       " 'open',\n",
       " 'bag',\n",
       " 'trump',\n",
       " 'little',\n",
       " 'dear',\n",
       " 'look',\n",
       " 'few',\n",
       " 'ago',\n",
       " 'job',\n",
       " 'item',\n",
       " 'may',\n",
       " 'items',\n",
       " 'around',\n",
       " 'accountable',\n",
       " 'person',\n",
       " 'shame',\n",
       " 'future',\n",
       " 'disappointed',\n",
       " 'friends',\n",
       " 'gmo',\n",
       " 'else',\n",
       " 'big',\n",
       " 'thought',\n",
       " 'looking',\n",
       " 'hour',\n",
       " 'christmas',\n",
       " 'kroger',\n",
       " 'taking',\n",
       " 'enough',\n",
       " 'different',\n",
       " 'waiting',\n",
       " 'try',\n",
       " 'things',\n",
       " 'months',\n",
       " 'ticket',\n",
       " 'information',\n",
       " 'guess',\n",
       " 'found',\n",
       " 'already',\n",
       " 'product',\n",
       " 'left',\n",
       " 'life',\n",
       " 'employee',\n",
       " 'weeks',\n",
       " 'lot',\n",
       " 'fee',\n",
       " 'simply',\n",
       " 'sent',\n",
       " 'feel',\n",
       " 'night',\n",
       " 'instead',\n",
       " 'aa',\n",
       " 'understand',\n",
       " 'least',\n",
       " 'believe',\n",
       " 'post',\n",
       " 'gave',\n",
       " 'contact',\n",
       " 'accounts',\n",
       " 'trip',\n",
       " 'fees',\n",
       " 'ask',\n",
       " '20',\n",
       " 'husband',\n",
       " 'show',\n",
       " 'send',\n",
       " 'sell',\n",
       " 'plane',\n",
       " 'actually',\n",
       " 'thats',\n",
       " 'cash',\n",
       " 'airport',\n",
       " 'morning',\n",
       " 'less',\n",
       " 'hey',\n",
       " 'start',\n",
       " 'discover',\n",
       " 'yesterday',\n",
       " 'purchased',\n",
       " 'payment',\n",
       " 'dollar',\n",
       " 'petsmart',\n",
       " 'site',\n",
       " 'reason',\n",
       " 'once',\n",
       " 'flying',\n",
       " 'chocolate',\n",
       " 'question',\n",
       " 'cannot',\n",
       " 'both',\n",
       " 'wells',\n",
       " 'pharmacy',\n",
       " 'system',\n",
       " 'immediately',\n",
       " 'ill',\n",
       " 'finally',\n",
       " 'aware',\n",
       " 'staff',\n",
       " 'sales',\n",
       " 'horrible',\n",
       " 'full',\n",
       " 'own',\n",
       " 'fargo',\n",
       " 'each',\n",
       " 'says',\n",
       " 'dollars',\n",
       " 'dog',\n",
       " 'deal',\n",
       " 'bring',\n",
       " 'almost',\n",
       " 'though',\n",
       " 'seems',\n",
       " 'rewards',\n",
       " 'offer',\n",
       " 'however',\n",
       " 'held',\n",
       " 'everything',\n",
       " 'spend',\n",
       " 'rude',\n",
       " 'needs',\n",
       " 'loyal',\n",
       " 'commit',\n",
       " 'cards',\n",
       " 'youre',\n",
       " 'three',\n",
       " 'house',\n",
       " 'charged',\n",
       " 'came',\n",
       " 'against',\n",
       " 'withdraw',\n",
       " 'wish',\n",
       " 'spent',\n",
       " 'later',\n",
       " 'close',\n",
       " 'available',\n",
       " 'answer',\n",
       " 'amount',\n",
       " 'standing',\n",
       " 'soon',\n",
       " 'several',\n",
       " 'saying',\n",
       " 'hersheys',\n",
       " 'given',\n",
       " 'end',\n",
       " 'seat',\n",
       " 'live',\n",
       " 'talk',\n",
       " 'mr',\n",
       " 'coming',\n",
       " 'agent',\n",
       " '6',\n",
       " 'whats',\n",
       " 'travel',\n",
       " 'sorry',\n",
       " 'needed',\n",
       " 'banking',\n",
       " '15',\n",
       " 'murder',\n",
       " 'miles',\n",
       " 'message',\n",
       " 'kids',\n",
       " 'extra',\n",
       " 'couldnt',\n",
       " 'computer',\n",
       " 'anymore',\n",
       " 'small',\n",
       " 'shouldnt',\n",
       " 'isnt',\n",
       " 'happened',\n",
       " 'game',\n",
       " 'foods',\n",
       " 'filed',\n",
       " 'protection',\n",
       " 'protect',\n",
       " 'program',\n",
       " 'id',\n",
       " 'friday',\n",
       " 'either',\n",
       " 'continue',\n",
       " '30',\n",
       " 'vs',\n",
       " 'response',\n",
       " 'maybe',\n",
       " 'loan',\n",
       " 'friendly',\n",
       " 'favorite',\n",
       " 'aid',\n",
       " 'set',\n",
       " 'rite',\n",
       " 'hi',\n",
       " 'hard',\n",
       " 'v',\n",
       " 'might',\n",
       " 'heard',\n",
       " 'facebook',\n",
       " 'treated',\n",
       " 'ensure',\n",
       " 'department',\n",
       " 'children',\n",
       " 'bofa',\n",
       " 'systems',\n",
       " 'submitted',\n",
       " 'read',\n",
       " 'prices',\n",
       " 'past',\n",
       " 'man',\n",
       " 'cost',\n",
       " 'closed',\n",
       " 'checking',\n",
       " 'black',\n",
       " 'b',\n",
       " '12',\n",
       " 'situation',\n",
       " 'mortgage',\n",
       " 'awesome',\n",
       " 'real',\n",
       " 'miss',\n",
       " 'fix',\n",
       " 'far',\n",
       " 'run',\n",
       " 'part',\n",
       " 'justice',\n",
       " 'itself',\n",
       " 'giving',\n",
       " 'fact',\n",
       " 'branch',\n",
       " 'bags',\n",
       " 'wasnt',\n",
       " 'stand',\n",
       " 'soup',\n",
       " 'oh',\n",
       " 'companies',\n",
       " 'buying',\n",
       " 'problems',\n",
       " 'matter',\n",
       " 'criminals',\n",
       " 'box',\n",
       " 'banks',\n",
       " '25',\n",
       " 'poor',\n",
       " 'half',\n",
       " 'air',\n",
       " '50',\n",
       " 'top',\n",
       " 'seriously',\n",
       " 'pick',\n",
       " 'others',\n",
       " 'attempts',\n",
       " 'appreciate',\n",
       " 'wouldnt',\n",
       " 'wonderful',\n",
       " 'receipt',\n",
       " 'ok',\n",
       " 'late',\n",
       " 'cashier',\n",
       " 'started',\n",
       " 'makes',\n",
       " 'immunity',\n",
       " 'criminal',\n",
       " 'stock',\n",
       " 'short',\n",
       " 'process',\n",
       " 'point',\n",
       " 'member',\n",
       " 'kind',\n",
       " 'decision',\n",
       " '7',\n",
       " 'special',\n",
       " 'son',\n",
       " 'seeking',\n",
       " 'refund',\n",
       " 'receive',\n",
       " 'gas',\n",
       " 'committed',\n",
       " '100',\n",
       " 'military',\n",
       " 'luggage',\n",
       " 'list',\n",
       " 'kraft',\n",
       " 'deposit',\n",
       " 'add',\n",
       " 'possible',\n",
       " 'shells',\n",
       " 'second',\n",
       " 'save',\n",
       " 'sad',\n",
       " 'plus',\n",
       " 'passengers',\n",
       " 'myself',\n",
       " 'lose',\n",
       " 'gone',\n",
       " 'drive',\n",
       " 'donald',\n",
       " 'absolutely',\n",
       " 'world',\n",
       " 'whole',\n",
       " 'undermine',\n",
       " 'speak',\n",
       " 'selling',\n",
       " 'must',\n",
       " 'leave',\n",
       " 'idea',\n",
       " 'hate',\n",
       " 'dump',\n",
       " 'compound',\n",
       " 'choice',\n",
       " 'car',\n",
       " 'worth',\n",
       " 'ready',\n",
       " 'checked',\n",
       " 'boycott',\n",
       " 'ad',\n",
       " 'yes',\n",
       " 'telling',\n",
       " 'states',\n",
       " 'saw',\n",
       " 'rep',\n",
       " 'helping',\n",
       " 'helpful',\n",
       " 'gamestop',\n",
       " 'delayed',\n",
       " 'book',\n",
       " 'bill',\n",
       " 'address',\n",
       " 'true',\n",
       " 'signing',\n",
       " 'ordered',\n",
       " 'murderers',\n",
       " 'families',\n",
       " 'country',\n",
       " 'asking',\n",
       " 'supporting',\n",
       " 'prescription',\n",
       " 'liability',\n",
       " 'insurance',\n",
       " 'during',\n",
       " 'date',\n",
       " 'calls',\n",
       " 'area',\n",
       " 'allow',\n",
       " 'elsewhere',\n",
       " 'community',\n",
       " 'brand',\n",
       " 'behind',\n",
       " 'app',\n",
       " 'amazing',\n",
       " 'abroad',\n",
       " 'move',\n",
       " 'label',\n",
       " 'especially',\n",
       " 'under',\n",
       " 'twice',\n",
       " 'taken',\n",
       " 'recently',\n",
       " 'quest',\n",
       " 'cancelled',\n",
       " 'spoke',\n",
       " 'points',\n",
       " 'pet',\n",
       " 'issues',\n",
       " 'info',\n",
       " 'hello',\n",
       " 'front',\n",
       " 'dicks',\n",
       " 'balance',\n",
       " '37',\n",
       " '2012',\n",
       " 'pets',\n",
       " 'opened',\n",
       " 'office',\n",
       " 'location',\n",
       " 'havent',\n",
       " 'gate',\n",
       " 'forward',\n",
       " 'etc',\n",
       " 'delorenzo',\n",
       " 'closing',\n",
       " 'calling',\n",
       " 'autozone',\n",
       " 'access',\n",
       " 'weekend',\n",
       " 'sucks',\n",
       " 'stuff',\n",
       " 'ones',\n",
       " 'hear',\n",
       " 'group',\n",
       " 'eat',\n",
       " 'corn',\n",
       " 'carry',\n",
       " 'wow',\n",
       " 'tickets',\n",
       " 'seats',\n",
       " 'labeling',\n",
       " 'happen',\n",
       " 'daughter',\n",
       " 'animal',\n",
       " 'young',\n",
       " 'upset',\n",
       " 'tonight',\n",
       " 'provide',\n",
       " 'decided',\n",
       " 'within',\n",
       " 'terrible',\n",
       " 'size',\n",
       " 'request',\n",
       " 'register',\n",
       " 'couple',\n",
       " 'city',\n",
       " 'changed',\n",
       " 'ally',\n",
       " '8',\n",
       " 'wonder',\n",
       " 'talking',\n",
       " 'services',\n",
       " 'savings',\n",
       " 'mistake',\n",
       " 'friend',\n",
       " 'deals',\n",
       " 'code',\n",
       " 'child',\n",
       " 'word',\n",
       " 'turn',\n",
       " 'sick',\n",
       " 'huge',\n",
       " 'complaint',\n",
       " 'chance',\n",
       " 'supposed',\n",
       " 'story',\n",
       " 'sign',\n",
       " 'security',\n",
       " 'public',\n",
       " 'lady',\n",
       " 'knew',\n",
       " 'informed',\n",
       " 'gets',\n",
       " 'cut',\n",
       " 'class',\n",
       " 'total',\n",
       " 'tomorrow',\n",
       " 'probably',\n",
       " 'plan',\n",
       " 'paying',\n",
       " 'offered',\n",
       " 'news',\n",
       " 'high',\n",
       " 'goes',\n",
       " 'funds',\n",
       " 'error',\n",
       " 'comes',\n",
       " 'booked',\n",
       " 'works',\n",
       " 'treat',\n",
       " 'swa',\n",
       " 'school',\n",
       " 'rather',\n",
       " 'letter',\n",
       " 'interest',\n",
       " 'dogs',\n",
       " 'counter',\n",
       " 'completely',\n",
       " 'chicken',\n",
       " 'board',\n",
       " 'tv',\n",
       " 'suck',\n",
       " 'sold',\n",
       " 'share',\n",
       " 'print',\n",
       " 'holiday',\n",
       " 'extremely',\n",
       " 'cheese',\n",
       " 'campbells',\n",
       " 'yall',\n",
       " 'sweet',\n",
       " 'seen',\n",
       " 'seem',\n",
       " 'mail',\n",
       " 'lack',\n",
       " 'hershey',\n",
       " 'general',\n",
       " 'games',\n",
       " 'enjoy',\n",
       " 'debit',\n",
       " 'crew',\n",
       " 'charges',\n",
       " 'boycotting',\n",
       " 'between',\n",
       " 'supervisor',\n",
       " 'regarding',\n",
       " 'per',\n",
       " 'monday',\n",
       " 'mean',\n",
       " 'international',\n",
       " 'discount',\n",
       " 'direct',\n",
       " 'course',\n",
       " 'chicago',\n",
       " 'water',\n",
       " 'warranty',\n",
       " 'safe',\n",
       " 'ridiculous',\n",
       " 'representative',\n",
       " 'organization',\n",
       " 'market',\n",
       " 'looked',\n",
       " 'hit',\n",
       " 'baggage',\n",
       " 'airways',\n",
       " 'wondering',\n",
       " 'via',\n",
       " 'takes',\n",
       " 'recent',\n",
       " 'putting',\n",
       " 'link',\n",
       " 'easy',\n",
       " 'cream',\n",
       " 'consider',\n",
       " 'center',\n",
       " 'won',\n",
       " 'thousands',\n",
       " 'team',\n",
       " 'remove',\n",
       " 'questions',\n",
       " 'option',\n",
       " 'missed',\n",
       " 'members',\n",
       " 'leaving',\n",
       " 'including',\n",
       " 'guy',\n",
       " 'correct',\n",
       " 'choose',\n",
       " 'cancel',\n",
       " 'california',\n",
       " '1000',\n",
       " 'status',\n",
       " 'refuse',\n",
       " 'ipad',\n",
       " 'grocery',\n",
       " 'form',\n",
       " 'express',\n",
       " 'explain',\n",
       " 'clearly',\n",
       " '2nd',\n",
       " 'wife',\n",
       " 'unless',\n",
       " 'spending',\n",
       " 'single',\n",
       " 'shipping',\n",
       " 'sense',\n",
       " 'pass',\n",
       " 'mom',\n",
       " 'loved',\n",
       " 'apparently',\n",
       " 'agents',\n",
       " 'together',\n",
       " 'saturday',\n",
       " 'picture',\n",
       " 'million',\n",
       " 'gotten',\n",
       " 'economy',\n",
       " 'earlier',\n",
       " 'cereal',\n",
       " 'animals',\n",
       " 'woman',\n",
       " 'truly',\n",
       " 'town',\n",
       " 'returned',\n",
       " 'personal',\n",
       " 'payments',\n",
       " 'negative',\n",
       " 'mobile',\n",
       " 'hsus',\n",
       " 'frustrating',\n",
       " 'auto',\n",
       " 'arrived',\n",
       " 'above',\n",
       " 'youve',\n",
       " 'walked',\n",
       " 'simple',\n",
       " 'san',\n",
       " 'refused',\n",
       " 'paper',\n",
       " 'noticed',\n",
       " 'means',\n",
       " 'ingredients',\n",
       " 'four',\n",
       " 'flew',\n",
       " 'fire',\n",
       " 'filled',\n",
       " 'eating',\n",
       " 'along',\n",
       " 'ads',\n",
       " '200',\n",
       " 'traveling',\n",
       " 'till',\n",
       " 'state',\n",
       " 'sincerely',\n",
       " 'power',\n",
       " 'opening',\n",
       " 'n',\n",
       " 'looks',\n",
       " 'large',\n",
       " 'door',\n",
       " 'cause',\n",
       " 'birthday',\n",
       " 'beyond',\n",
       " 'sitting',\n",
       " 'purchasing',\n",
       " 'posting',\n",
       " 'pictures',\n",
       " 'ny',\n",
       " 'multiple',\n",
       " 'low',\n",
       " 'lets',\n",
       " 'honor',\n",
       " 'expect',\n",
       " 'early',\n",
       " 'consumer',\n",
       " 'connection',\n",
       " 'bit',\n",
       " '500',\n",
       " 'walk',\n",
       " 'type',\n",
       " 'treats',\n",
       " 'transferred',\n",
       " 'thanksgiving',\n",
       " 'stopped',\n",
       " 'remember',\n",
       " 'regular',\n",
       " 'prescriptions',\n",
       " 'options',\n",
       " 'notice',\n",
       " 'management',\n",
       " 'inside',\n",
       " 'hotel',\n",
       " 'happens',\n",
       " 'frustrated',\n",
       " 'fine',\n",
       " 'commercial',\n",
       " 'boarding',\n",
       " 'atm',\n",
       " '24',\n",
       " 'step',\n",
       " 'reward',\n",
       " 'quality',\n",
       " 'posted',\n",
       " 'picked',\n",
       " 'photo',\n",
       " 'law',\n",
       " 'hand',\n",
       " 'face',\n",
       " 'entire',\n",
       " 'charging',\n",
       " 'candy',\n",
       " 'ca',\n",
       " 'americans',\n",
       " 'worse',\n",
       " 'wants',\n",
       " 'value',\n",
       " 'usually',\n",
       " 'theyre',\n",
       " 'sunday',\n",
       " 'south',\n",
       " 'pm',\n",
       " 'kept',\n",
       " 'health',\n",
       " 'follow',\n",
       " 'double',\n",
       " 'xbox',\n",
       " 'win',\n",
       " 'visit',\n",
       " 'video',\n",
       " 'vegas',\n",
       " 'upgrade',\n",
       " 'trust',\n",
       " 'totally',\n",
       " 'suntrust',\n",
       " 'somewhere',\n",
       " 'mother',\n",
       " 'match',\n",
       " 'losing',\n",
       " 'jobs',\n",
       " 'hung',\n",
       " 'forced',\n",
       " 'financial',\n",
       " 'enter',\n",
       " 'corporation',\n",
       " 'consumers',\n",
       " 'claim',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ad13d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19465"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorize_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6b58d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = keras.Sequential()\n",
    "\n",
    "model_rnn.add(vectorize_layer)\n",
    "\n",
    "model_rnn.add(keras.layers.Embedding(\n",
    "    input_dim = len(vectorize_layer.get_vocabulary()),\n",
    "    output_dim = 128,\n",
    "    mask_zero = True\n",
    "))\n",
    "\n",
    "model_rnn.add(keras.layers.SimpleRNN(128)) \n",
    "\n",
    "model_rnn.add(keras.layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "# configure training / optimization\n",
    "model_rnn.compile(loss = keras.losses.CategoricalCrossentropy(),\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f9f9e756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 20s 374ms/step - loss: 0.9692 - accuracy: 0.5704 - val_loss: 0.8987 - val_accuracy: 0.6930\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 18s 361ms/step - loss: 0.7227 - accuracy: 0.7481 - val_loss: 0.8208 - val_accuracy: 0.7112\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 18s 359ms/step - loss: 0.3768 - accuracy: 0.8965 - val_loss: 0.6703 - val_accuracy: 0.7426\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 18s 365ms/step - loss: 0.1081 - accuracy: 0.9812 - val_loss: 0.7902 - val_accuracy: 0.6962\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 17s 344ms/step - loss: 0.0413 - accuracy: 0.9950 - val_loss: 0.7561 - val_accuracy: 0.7608\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 17s 343ms/step - loss: 0.0224 - accuracy: 0.9980 - val_loss: 0.8124 - val_accuracy: 0.7514\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 17s 341ms/step - loss: 0.0147 - accuracy: 0.9991 - val_loss: 0.8433 - val_accuracy: 0.7589\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 18s 352ms/step - loss: 0.0108 - accuracy: 0.9989 - val_loss: 0.8780 - val_accuracy: 0.7571\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 18s 362ms/step - loss: 0.0084 - accuracy: 0.9991 - val_loss: 0.9167 - val_accuracy: 0.7539\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 17s 347ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.9404 - val_accuracy: 0.7577\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 18s 365ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.9641 - val_accuracy: 0.7520\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 18s 353ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.9882 - val_accuracy: 0.7533\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 17s 351ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 1.0137 - val_accuracy: 0.7546\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 16s 328ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 1.0331 - val_accuracy: 0.7445\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 17s 341ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 1.0476 - val_accuracy: 0.7470\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 17s 348ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 1.0608 - val_accuracy: 0.7489\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 17s 347ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 1.0781 - val_accuracy: 0.7458\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 17s 336ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 1.0950 - val_accuracy: 0.7464\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 17s 346ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 1.1060 - val_accuracy: 0.7470\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 17s 344ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 1.1226 - val_accuracy: 0.7464\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 17s 342ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 1.1277 - val_accuracy: 0.7458\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 17s 344ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 1.1453 - val_accuracy: 0.7426\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 17s 338ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 1.1559 - val_accuracy: 0.7445\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 17s 326ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.1650 - val_accuracy: 0.7407\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 18s 352ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 1.1679 - val_accuracy: 0.7451\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 18s 349ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 1.1894 - val_accuracy: 0.7414\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 18s 347ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.1887 - val_accuracy: 0.7470\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 17s 341ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.1961 - val_accuracy: 0.7420\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 17s 345ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 1.2088 - val_accuracy: 0.7433\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 18s 372ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.2106 - val_accuracy: 0.7433\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 18s 352ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.2231 - val_accuracy: 0.7426\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 21s 417ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.2355 - val_accuracy: 0.7420\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 17s 337ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 1.2365 - val_accuracy: 0.7395\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 17s 348ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 1.2451 - val_accuracy: 0.7414\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 18s 364ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 1.2451 - val_accuracy: 0.7420\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 18s 359ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 1.2588 - val_accuracy: 0.7395\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 18s 353ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.2586 - val_accuracy: 0.7420\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 17s 349ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 1.2706 - val_accuracy: 0.7407\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 17s 345ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 1.2727 - val_accuracy: 0.7420\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 18s 358ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 1.2775 - val_accuracy: 0.7401\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 18s 352ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 1.2876 - val_accuracy: 0.7407\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 18s 354ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 1.2933 - val_accuracy: 0.7407\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 18s 355ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.2901 - val_accuracy: 0.7401\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 17s 348ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.3049 - val_accuracy: 0.7389\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 17s 335ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 1.3138 - val_accuracy: 0.7389\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 18s 360ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 1.3164 - val_accuracy: 0.7420\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 17s 342ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 1.3174 - val_accuracy: 0.7395\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 17s 332ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 1.3233 - val_accuracy: 0.7414\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 17s 337ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.3239 - val_accuracy: 0.7420\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 18s 355ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 1.3345 - val_accuracy: 0.7414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5227f93d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training with 20% validation and 10 epochs.\n",
    "model_rnn.fit(x = text, y = label, validation_split = 0.2,\n",
    "              epochs=50, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "569125b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = keras.Sequential()\n",
    "\n",
    "model_lstm.add(vectorize_layer)\n",
    "\n",
    "model_lstm.add(keras.layers.Embedding(\n",
    "    input_dim = len(vectorize_layer.get_vocabulary()),\n",
    "    output_dim = 128,\n",
    "    mask_zero = True\n",
    "))\n",
    "\n",
    "model_lstm.add(keras.layers.GRU(128)) \n",
    "\n",
    "model_lstm.add(keras.layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "# configure training / optimization\n",
    "model_lstm.compile(loss = keras.losses.CategoricalCrossentropy(),\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fe116325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "50/50 [==============================] - 37s 671ms/step - loss: 0.9553 - accuracy: 0.5386 - val_loss: 0.6444 - val_accuracy: 0.7382\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.5256 - accuracy: 0.7940 - val_loss: 0.5102 - val_accuracy: 0.8010\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 31s 617ms/step - loss: 0.2517 - accuracy: 0.9160 - val_loss: 0.5984 - val_accuracy: 0.7853\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 31s 631ms/step - loss: 0.1220 - accuracy: 0.9587 - val_loss: 0.7511 - val_accuracy: 0.7897\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 32s 653ms/step - loss: 0.0652 - accuracy: 0.9808 - val_loss: 0.9529 - val_accuracy: 0.7841\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 31s 617ms/step - loss: 0.0383 - accuracy: 0.9887 - val_loss: 1.0995 - val_accuracy: 0.7784\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 33s 656ms/step - loss: 0.0288 - accuracy: 0.9917 - val_loss: 1.1165 - val_accuracy: 0.7627\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 30s 606ms/step - loss: 0.0335 - accuracy: 0.9909 - val_loss: 1.2931 - val_accuracy: 0.7746\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 30s 617ms/step - loss: 0.0342 - accuracy: 0.9906 - val_loss: 1.1792 - val_accuracy: 0.7709\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 30s 609ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 1.3618 - val_accuracy: 0.7659\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 31s 625ms/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 1.4007 - val_accuracy: 0.7640\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 30s 602ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 1.4401 - val_accuracy: 0.7577\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 30s 610ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 1.5402 - val_accuracy: 0.7815\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 30s 587ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 1.5022 - val_accuracy: 0.7696\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 31s 624ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 1.5403 - val_accuracy: 0.7765\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 30s 608ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 1.6204 - val_accuracy: 0.7772\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 1.7334 - val_accuracy: 0.7709\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 30s 595ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 1.7026 - val_accuracy: 0.7772\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 30s 612ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 1.8903 - val_accuracy: 0.7602\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 31s 617ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 1.7562 - val_accuracy: 0.7746\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 31s 614ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 1.8681 - val_accuracy: 0.7684\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 28s 561ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 1.9010 - val_accuracy: 0.7665\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 29s 585ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 1.9401 - val_accuracy: 0.7740\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 2.0019 - val_accuracy: 0.7627\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 30s 614ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 2.0024 - val_accuracy: 0.7709\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 29s 583ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 2.0343 - val_accuracy: 0.7652\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 30s 604ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 2.0609 - val_accuracy: 0.7696\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 30s 605ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 2.0752 - val_accuracy: 0.7677\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 30s 594ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 2.0976 - val_accuracy: 0.7652\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 30s 609ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 2.1366 - val_accuracy: 0.7690\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 31s 612ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 2.1636 - val_accuracy: 0.7690\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 30s 602ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 2.1759 - val_accuracy: 0.7659\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 31s 623ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 2.2151 - val_accuracy: 0.7671\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 31s 626ms/step - loss: 0.0020 - accuracy: 0.9991 - val_loss: 2.2298 - val_accuracy: 0.7677\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 30s 609ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 2.2032 - val_accuracy: 0.7659\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 30s 604ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 2.2312 - val_accuracy: 0.7646\n",
      "Epoch 37/50\n",
      "50/50 [==============================] - 31s 621ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 2.2505 - val_accuracy: 0.7640\n",
      "Epoch 38/50\n",
      "50/50 [==============================] - 31s 620ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 2.2768 - val_accuracy: 0.7640\n",
      "Epoch 39/50\n",
      "50/50 [==============================] - 29s 588ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 2.3073 - val_accuracy: 0.7621\n",
      "Epoch 40/50\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 2.2890 - val_accuracy: 0.7646\n",
      "Epoch 41/50\n",
      "50/50 [==============================] - 29s 577ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 2.3332 - val_accuracy: 0.7627\n",
      "Epoch 42/50\n",
      "50/50 [==============================] - 29s 588ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 2.3186 - val_accuracy: 0.7621\n",
      "Epoch 43/50\n",
      "50/50 [==============================] - 30s 589ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 2.3298 - val_accuracy: 0.7640\n",
      "Epoch 44/50\n",
      "50/50 [==============================] - 30s 596ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 2.3152 - val_accuracy: 0.7633\n",
      "Epoch 45/50\n",
      "50/50 [==============================] - 28s 572ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 2.2575 - val_accuracy: 0.7696\n",
      "Epoch 46/50\n",
      "50/50 [==============================] - 30s 601ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 2.2071 - val_accuracy: 0.7778\n",
      "Epoch 47/50\n",
      "50/50 [==============================] - 31s 613ms/step - loss: 0.1411 - accuracy: 0.9595 - val_loss: 1.2221 - val_accuracy: 0.7527\n",
      "Epoch 48/50\n",
      "50/50 [==============================] - 31s 615ms/step - loss: 0.1262 - accuracy: 0.9612 - val_loss: 0.9837 - val_accuracy: 0.7621\n",
      "Epoch 49/50\n",
      "50/50 [==============================] - 30s 599ms/step - loss: 0.0395 - accuracy: 0.9878 - val_loss: 1.1318 - val_accuracy: 0.7213\n",
      "Epoch 50/50\n",
      "50/50 [==============================] - 31s 618ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 1.3088 - val_accuracy: 0.7389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc527002a90>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training with 20% validation and 10 epochs.\n",
    "model_lstm.fit(x = text, y = label, validation_split = 0.2,\n",
    "              epochs=50, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a47a1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_prediction_file(model):\n",
    "    pred=model.predict(pred_text)\n",
    "    pred=pred.round()\n",
    "    dataset=unlabeled_dataset.drop('message',axis=1)\n",
    "    dataset['Appreciation_pred']=pred[:,0]\n",
    "    dataset['Complaint_pred']=pred[:,1]\n",
    "    dataset['Feedback_pred']=pred[:,1]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ec5b2321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 2s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction=get_prediction_file(model_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "110a9707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction2=get_prediction_file(model_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4af2bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction2.to_csv(\"predictions_rnn.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b780b3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'bert_en_cased_L-12_H-768_A-12' \n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "47a7732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38d1b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  net = tf.keras.layers.Dense(3, activation=\"softmax\", name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4f210ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.65379035 0.5198299  0.57074624]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "844a857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c7630701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  7/199 [>.............................] - ETA: 1:11:34 - loss: 1.7441 - f1_score: 0.1634"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [79]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optimization\u001b[38;5;241m.\u001b[39mcreate_optimizer(init_lr\u001b[38;5;241m=\u001b[39minit_lr,\n\u001b[1;32m      8\u001b[0m                                           num_train_steps\u001b[38;5;241m=\u001b[39mnum_train_steps,\n\u001b[1;32m      9\u001b[0m                                           num_warmup_steps\u001b[38;5;241m=\u001b[39mnum_warmup_steps,\n\u001b[1;32m     10\u001b[0m                                           optimizer_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madamw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m classifier_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     12\u001b[0m                          loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[1;32m     13\u001b[0m                          metrics\u001b[38;5;241m=\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mF1Score(\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m    879\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m--> 880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    908\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn\u001b[38;5;241m.\u001b[39m_function_spec  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    909\u001b[0m       \u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m    910\u001b[0m           args, kwds))\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39m_call_flat(   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    913\u001b[0m       filtered_flat_args,\n\u001b[1;32m    914\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds, inner_filtered_flat_args):\n\u001b[1;32m    917\u001b[0m   \u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m self._capture_by_value = capture_by_value\n\u001b[1;32m    132\u001b[0m self.tracing_count = 0\n\u001b[1;32m    133\u001b[0m # Maintein a dict of all captures: identifier -> lambda function. It's used\n\u001b[0;32m--> 134\u001b[0m # to get runtime values for all captures during ConcreteFunction dispatch,\n\u001b[1;32m    135\u001b[0m self._func_captures = capture_container.FunctionCaptures()\n\u001b[1;32m    136\u001b[0m self._lock = threading.RLock()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m arg_specs, kwarg_specs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstructured_input_signature\n\u001b[0;32m-> 1745\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39marg_names)\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;66;03m# If an explicit input_signature is provided to @tf.function, then any\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;66;03m# arguments with defaults that are not covered by that explicit signature\u001b[39;00m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;66;03m# are simply dropped from the signature.\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;66;03m# TODO(b/159639913) Look into whether dropping arguments with default values\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# from the signature is the right thing to do.\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m arg_names[:\u001b[38;5;28mlen\u001b[39m(arg_specs)]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_TapeGradientFunctions\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    372\u001b[0m   \u001b[38;5;124;03m\"\"\"Caches forward and backward functions compatible with eager gradients.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m  In contrast to the delayed-rewrite approach in\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m  `_DelayedRewriteGradientFunctions` which only works with delayed execution,\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m  the forward function generated by this class has a fixed set of outputs which\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m  may be preserved by a tape in order to compute gradients later.\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m \n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m  This class is abstract; its child classes differ in how many side outputs of\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m  the forward function their backward function accepts gradients for, which\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m  determines whether higher-order tape gradients are possible.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func_graph, attrs, func_graph_deleter,\n\u001b[1;32m    385\u001b[0m                forwardprop_input_indices, delayed_rewrite_functions,\n\u001b[1;32m    386\u001b[0m                need_gradients_for_jvps):\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph \u001b[38;5;241m=\u001b[39m func_graph\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m     53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = len(text)\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')\n",
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics.F1Score(3))\n",
    "history = classifier_model.fit(x = text, y = label, validation_split = 0.2,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1a6465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 50s 781ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_BERT=get_prediction_file(classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "824254c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_BERT.to_csv(\"submission_BERT.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c267c612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
